\documentclass[conference]{IEEEtran}
%\usepackage[titletoc]{appendix}
\usepackage{float}
\usepackage{graphicx}
\usepackage[pdftex,
			%final,
            pdfauthor={Adrien Raulot and Luc Gommans},
            pdftitle={TODO},
            pdfkeywords={TODO}]{hyperref}
\usepackage{wrapfig}
\usepackage{booktabs}
\hypersetup{
	colorlinks=true,       % false: boxed links; true: coloured links
	linkcolor=blue,        % colour of internal links
	citecolor=blue,        % colour of links to bibliography
	filecolor=magenta,     % colour of file links
	urlcolor=blue
}

\usepackage[
    backend=bibtex,
    style=numeric,
    sorting=none,
    maxcitenames=2
]{biblatex}

\usepackage{listings}
\lstset{breaklines, basicstyle=\small\ttfamily\footnotesize\bfseries}

\bibliography{references.bib}

\begin{document}

\title{DNS bitsquatting\\\vspace{5mm} \large  \today}
\author{
\IEEEauthorblockN{Adrien Raulot}
\IEEEauthorblockA{
Security and Network Engineering \\
University of Amsterdam \\
adrien.raulot@os3.nl}
\and
\IEEEauthorblockN{Luc Gommans}
\IEEEauthorblockA{
Security and Network Engineering \\
University of Amsterdam \\
os3-ot@lucgommans.nl}
}
\maketitle
\thispagestyle{plain}
\pagestyle{plain}

\begin{abstract}

	In this paper we will investigate the current state of random DNS bit flips.
	While random bit errors in a machine are not very common, the number of DNS
	queries performed worldwide is extremely large. This might lead one to query
	for a domain name, and subsequently connect to the resulting IP address, which
	one never intended to connect to.

\end{abstract}

\section{Introduction}

The vast majority of internet-connected computers perform DNS requests during
conventional use. Because the requests are so ubiquitous, there is reason to
suspect that sometimes, due to random variations, errors might naturally occur.
When an error occurs, one might query for and subsequently connect to a domain
which one never intended to communicate with.

In this paper we will investigate likely causes for bit flips in desktop
computers and attempt to determine whether the resulting attack, bitsquatting,
is still viable.

%TODO: insert a disorderly substitute for a table of contents here, because that's how Science(TM) likes it.


\section{Research Questions}\label{sec:researchq}

Our main research question is:
{\it Is bitsquatting a viable attack?}

\vspace{0.1cm}

\noindent{} This main research question divides in four sub-questions:

\begin{enumerate}
    \item What could a bitsquatting attack be used for?
	\item What circumstances cause random bit errors?
	\item Can we detect random bit errors currently occurring around the world?
	\item Are organisations mitigating the risk by pre-emptively purchasing
	      bitsquat domains?
\end{enumerate}

One important exclusion is network equipment. In this work, we only looked at
bit flips occurring on a common computer. Mobile equipment is only partially
targeted: to answer the third sub-question, we purposefully registered a domain
that is popular on mobile devices, but we did not ourselves attempt to trigger
memory corruption on a mobile device. If this occurs a lot on mobile devices,
we should observe a larger number of hits on that domain.


\section{Ethical Considerations}\label{sec:ethics}

Most of our work will focus on attempting to find causes of random bit errors.
However, in order to learn whether random bit errors are currently occuring in
practice, we will need to work with real domains and user data. This data is
kept confidential and will be destroyed after completion of the project. The
domains we register will not be used for anything other than determining
whether this is the result of a random bit error.


\section{Related Work}\label{sec:relwork}

In 2011, Artem Dinaburg presented for the first time the bitsquatting attack at
the DEFCON 19 security conference. In his
whitepaper\cite{dinaburg2011bitsquatting}, he describes bitsquatting as an
attack relying on random bit errors to redirect connections intended for
popular domains to domains registered by malicious entities. Since 2011, very
few research papers have been published about bitsquatting, hence this
research. Another research from 2011 by Nick et
al.\cite{nikiforakis2013bitsquatting} showed that bitsquatting was still
popular by monitoring newly registered bitsquatting domains over a period of
270 days. In this period, a total of 5 366 different bitsquatting domains were
registered, targeting 491 out of the Alexa top 500 domains.

\section{Experiment 1: Heating}

Although random bit flips are theoretically possible, the unlikeliness of a bit
flip in practice is important. Bit flips or soft errors are more likely to
occur in certain circumstances such as high temperature, low voltage, high
speed, alpha particles, cosmic rays, and others. This not only may have an
impact on the applications running on a system, but also raises security
concerns as attacks, such as the bitsquatting attack we describe in this paper
may take advantage of soft errors. During this research, we mainly focused on
producing soft errors in memory modules, although we also tested and monitored
the hard disk and the network for bit flips. Nowadays, Error-Correcting Code
(ECC) memory is commonly used in most computers where data corruption has a
large impact.

From the different fault injection techniques known to
exist\cite{barenghi2012fault}, we decided to use heat. This technique is
realistic of situations where desktop computers, servers and smartphones are
impacted by high temperatures and it is a relatively cheap technique to set up.
Because this technique could damage the hardware, we were careful to place the
disposable hardware in a safe environment and constantly monitor the
temperature. The latter, however, has been more difficult than we expected, as
we were not able to retrieve thermal values from the system. To remedy this, we
monitored the hard drive temperature as an indicator and manually measured the
temperature of the CPU and memory with a infrared temperature sensor gun.

We acquired a disposable desktop to experiment on and implemented three types
of test program to monitor bit flips:

% TODO: For each, quote appendix
%TODO: I don't like this style of subsubsections. Maybe documentclass article instead?
% A: Agreed, I still like the IEEE style though. Will do the appendix tomorrow.
% L: I made these subsections for unrelated reasons (though it's a nice side-effect). Not sure this point is still relevant ^^
\subsection{Memory test}

Our memory tester retrieves $(2^{12})-1$ bytes of random data from
\texttt{/dev/urandom} to use as random pattern. We configure it to allocate
95\% of free memory, which it fills with this random pattern. The amount of
random bytes is chosen to explicitly not align to a memory page, so that each
page contains a new byte as first byte. A few redundant copies of the correct
pattern are kept separately.

After writing the pattern to the allocated memory, which consists of several
gigabytes so it cannot still be in CPU caches, we read the data again
sequentially and compare it against our pattern. We also make sure that the
pattern's copies are all equal.

After a few iterations, the random pattern is refreshed by reading new data
from \texttt{/dev/urandom}. If some patterns are more susceptible to
alterations than others, this should hopefully reveal that. Upon discovery of
an error, both the correct pattern and the pattern which we found instead are
logged.

\subsection{Disk test}

The disk test is similar to the memory test because it also reads an uneven
number of bytes from \texttt{/dev/urandom} and writes that to a large file on
disk. Here, too, we made sure that the file is large enough not to fit in
memory caches, and the pattern is refreshed after a few iterations of writing
and reading.

The main difference is that we do not keep redundant copies of the correct
pattern, as we are not attempting to detect memory corruption here. Any memory
corruption should be evident from the other program.

The source code is available on Github: %TODO

\subsection{Network test}

The network test consists of two parts: a transmitter and a receiver. We used a
servers (in the same building) to transmit the data, and ran a receiver on the
experimental hardware. The packets transmitted are based on UDP, containing
1200 bytes payload. The first byte is a tracking number: it will increment
every time the payload changes. The last 32 bytes are a sha-256 hash of the
rest of the payload. Finally, the remainder of the payload is, again, data read
from \texttt{/dev/urandom}, and is changed every 30 seconds.

The incremental number allows us to do a byte-by-byte check of the data, to
compare it against the previously received packets. If it is unequal, we know
that the payload changed and that we should recompute the hash. If the data was
not equal, the hash would also be recomputed because this should no longer
match. If it does not match, we log the last known correct contents and the
corrupted contents.

Data was transmitted at a rate of about 800 megabits per second (bursting 50
packets and then calling nanosleep). We checked for packet loss, and this was
low. This only occurred when the target system was too busy to drain its
receive buffer, and was not caused by network equipment. We consider this to
have no impact on our results.

%TODO source code

\subsection{Desktop setup}

The desktop contains $2\times2$GB DDR2 RAM memory, an Intel Pentium D processor
and a 2TB Hitachi hard disk drive. More recent hardware was not considered
disposable by the university and therefore off limits for any sort of
experiment. The only alternative was an old server with ECC memory, which we
considered unfit for our purpose. Our CPU did not seem to contain a readable
temperature sensor: online we find many posts of users, on both Linux-based and
Windows operating systems, who find that they are unable to read the
temperature sensor. To have some notion of the machine's temperature, we used a
handheld infrared thermometer and the hard drive temperature.

In the machine, we created an isolated air inlet for the power supply unit
(PSU) and otherwise taped off all air intakes and outtakes. Aside from the PSU,
the CPU fan is the only fan in the system, which we left plugged in: this
circulates the hot air through the case and heats up other components such as
the memory.

During the tests, we run the three scripts in parallel. The CPU is a dual core
without hyperthreading, so our network receive and RAM test scripts could run
in parallel at nearly full speed. The disk test script also ran at full speed,
since the majority of the time was spent on I/O. This also had the effect of
putting the system under full load, generating a lot of heat.

Because the machine did not reach thermal cut-off temperature and did not
produce any bit errors yet, we later also covered it with a cloth to prevent
heat from dissipating through the metal cover. While this had a bigger impact
on the overall internal temperature, we were not able to produce any bit flips
or reach cut-off temperature. Finally, we attempted heating the memory modules
with a hair dryer, similar to the memory corruption experiments described by
\cite{jvm}. This experiment was halted when the hair dryer started melting and the
computer continued to run without any issues.

\subsection{Experiment 1: Results}

The following table shows milestones in the temperature increase during the
experiments:

%TODO: Very basic for now, more for clear visualization
\begin{table}[H]
  \centering
  \caption{Temperature levels during experiments}
  \label{table-temp}
  \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Component}   & \textbf{Min. (Celsius)} & \textbf{Max. (Celsius)}\\ \hline
    CPU   & 55 & 96 \\ \hline
    Memory & N/A & 90 \\ \hline
    Disk & 44 & 60 \\ \hline
   \end{tabular}
\end{table}


\section{Experiment 2: Bitsquatting}

For our second experiment, we registered and monitored 5 domains:

\begin{itemize}
  \item \texttt{eoogle.be.}
  \item \texttt{eoogle.nl.}
  \item \texttt{eoogle.co.uk.}
  \item \texttt{whatsapx.net.}
  \item \texttt{a9u9h.nl.}
\end{itemize}

The latter is a control domain, registered to be able to see the difference
between a bitsquatting domain and any other, unlisted domain. We picked the
name using a random number generator to make sure users did not stumble upon it
by accident. The name is short, so that it can be brute-forced by NSEC3 walks
(the \texttt{.nl} zone is DNSSEC-enabled). If our other domains are being found
via this method, then we will also see this on our control domain, and we know
that this traffic does not originate from random bit flips.

The bitsquat domains were chosen because we expect they get a lot of hits, and
because they should give a diversity of devices. For example, the WhatsApp
mobile application uses \texttt{whatsapp.net} rather than
\texttt{whatsapp.com}.

In table \ref{tab:bits} we show which bits were flipped for each domain.

\begin{table}[H]
  \centering
  \caption{Bitsquatting vs. original domain names}
  \label{tab:bits}
  \begin{tabular}{|l|l|l|}
    \hline
    \textbf{Domain}   & \textbf{Bits} \\ \hline
    eoogle   & 01100101... \\ \hline
    google   & 011001\textbf{1}1... \\ \hline
    whatsapx & ...01111000 \\ \hline
    whatsapp & ...0111\textbf{0}000 \\ \hline
   \end{tabular}
\end{table}

%TODO this paragraph should be separate somewhere
We noticed that for many domains which we would have liked to register, such as
bitsquats of \texttt{google.com} or \texttt{facebook.com}, the domains were
already occupied. For \texttt{google.com}, many of the domains are owned by
Google, but a few are not. Generating bitsquat domains is not difficult and
domains are not expensive, so we assume this was not an attempt at preventing
bitsquatting. For \texttt{facebook.com}, the situation is reversed: some are
owned by Facebook, and many are owned by external parties. Many of the bitsquat
domains lead to websites with advertisements. For other popular domains, we
notice similar patterns. This answers one of our research questions: companies
do not seem to be trying to prevent bitsquatting.

To gather the results for the domains we registered, we ran a DNS server for
all domains. For each domain, we returned a unique IP address of ours.
Hypothetically, we would see a client with a random bit error query for
\texttt{e19.whatsapx.net}, give it the IP address \texttt{145.100.108.252}, and
then observe it attempting to build a TCP connection with that IP address on a
port used by WhatsApp.

We used tcpdump's pcap-writing functionality to monitor this usage. Each of the
used IP addresses referred to the same server, making monitoring easier.


\subsection{Experiment 2: Results}

The control domain received 3 500 hits from the registrar (SIDN) and partners
(OpenIntel). These queried for various record types for the domain and the
subdomains \texttt{www}, \texttt{\_dmarc} and \texttt{\_domainkey}.

The other domains got many hits. It appears that \texttt{.co.uk} domains are
publicly listed, as we received 52 700 unsolicited queries of various types (A,
AAAA, TXT, NS, MX, etc.). In contrast, \texttt{eoogle.be} saw 12 000 queries
and \texttt{eoogle.nl} saw 6 600.

In 2011, Dinaburg\cite{dinaburg2011bitsquatting} recorded 52 000 bitsquat
requests over a period of 7 months, using 29 domains. This comes down to about
8.4 requests per domain per day. Perhaps memory got less error-prone to the
extent that the increased usage of the internet since 2011 is negated, but that
seems doubtful. We should probably see at least an equal number of requests.
However, to find those within a total of 169 700 queries, turned out to be
quite difficult.

The results were loaded into a relational database for easier querying. We
filtered the data in various ways, such as only listing queries from IP
addresses that were seen only once (since those errors are supposed to be rare)
and were querying for a normal record type, such as A or AAAA. Investigating
this list by looking in the gathered pcaps, we find that these IP addresses
never follow up on the response they were given. In some cases, a completely
different IP address (sometimes from a different continent, compared to the
original address) immediately attempts to contact the IP address that we
returned. They often attempt to contact a random port, not used by the service
we are bitsquatting.

Another query we attempted filters on addresses which we only saw 1-4 times and
which queried for both the A and AAAA records. It is typical to query for both,
so a legitimate client should do that. This yielded only 58 records: some from
Google and some from DigitalOcean, but also some promising-looking resolvers
such as from Level3. Looking in pcaps again, we found no normal follow-up
traffic.

No matter how we cut or slice the dataset, in no case does an IP address show
both normal resolver behaviour and follow up with normal traffic. Some of the
ones without follow-up traffic could be caused by bit errors, as a response for
the wrong query name might be ignored (if a resolver queries for A and gets an
answer for B, it might ignore it depending on where the error occurred), but
we cannot verify this with any certainty.

We also noticed a large number of queries from many different IP addresses at
Amazon AWS and Google (presumably their AWS-equivalent), as well as various
research institutes and other services which advertise themselves as DNS
scanners.

% TODO: check if complete


\section{Experiment 3: Rowhammer}

High memory densities create an increased rate of electromagnetic interactions
between memory cells\cite{kim2014flipping}. Our third experiment focuses on
accidental or intentional leaking of currency into nearby cells, possibly
causing bit flips that way.

We first needed to assert how likely this is when one tries to do this
intentionally. To test this, we used two different test suites: one by the team
at Google's Project Zero\footnote{\url{https://github.com/google/rowhammer-test}}
and one by Gruss et al.\cite{gruss2016rowhammer}\footnote{\url{https://github.com/IAIK/rowhammerjs}}.
From the latter, we ran the general tests, the specific one for our Ivy Bridge
hardware, and the JavaScript-based one.


\subsection{Experiment 3: Results}

The experimental hardware for experiment 1 is definitely not vulnerable, as the
memory is too old. On our server and workstations, the test suites did not
manage to trigger the attack. It appears that our hardware is not vulnerable.

%TODO this is rather brief, but not sure what more to say. Maybe something like "well if we can't even trigger it when we *try*..."


\section{Discussion}\label{sec:disc}

Since part of our bitsquatting domains ingress traffic was comming from
research institutes such as universities or laboratories and there is no easy
way to prevent this, it was very difficult to filter the noisy traffic out from
the legitimate and potentially bitflip-related traffic. This also poses a
design problem about bitsquatting experiments, the fact that researchers
monitoring the Internet for bitsquatting domains used by attackers end up
querying bitsquatting domains set up by other researchers. Moreover, traffic
monitoring experiments should be carried out during a longer period, as three
weeks is not enough to be able to clearly identify interesting traffic due to
bit flips.

\section{Conclusion}\label{sec:conc}

After several tentatives to produce bit flips in a desktop computer by using
the rowhammer attack as well as inventive ways of heating up the hardware, the
latter was surprisingly resilient and we could not observe any bit flips.
Registering and analyzing traffic from bitsquatting domains revealed that
bitsquatting domains are still very popular, although complications in
filtering out the traffic as well as abnormal behavior from clients contacting
the domains resulted in a very few legitimate requests.


\section{Future Work}\label{sec:futwork}

TODO

- test with mobile devices

- tests other than heat

- accidental rowhammer analysis

- more realistic (modern) hardware

- more test machines running more hours (day and night)


\printbibliography

\include{appendix}

\end{document}

